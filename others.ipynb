{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f86230c-9f89-43a2-9c18-27efec948724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from minisom import MiniSom\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026618c9-b0cb-47d7-9307-51000340ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_L3_info = Table.read('../dataset/L3_COSMOS2020_Richard_RefCat_2023DEC4_info.fits')\n",
    "df_L3_info = df_L3_info.to_pandas().sort_values(by = \"cosmos_id\")\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/Noiseless_phot_cosmos_nolines_refcat30k.txt'\n",
    "data_noiseless = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/NoisySphx_shallow_nolines_refcat30k.txt'\n",
    "data_all = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/NoisySphx_deep_nolines_refcat30k.txt'\n",
    "data_deep = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/SPHEREx_1sigma_noise.txt'\n",
    "data_1sig  = np.loadtxt(fname, skiprows=1)\n",
    "wl = data_1sig[:,0]\n",
    "sigma_all = data_1sig[:,1]\n",
    "sigma_deep = data_1sig[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d314ec-650a-4df8-bf07-57f2cefbe2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_data = pd.DataFrame(data_all[:, 0::2]).dropna().to_numpy()\n",
    "shallow_info = df_L3_info[-pd.DataFrame(data_all[:, 0::2]).isna()[0]]\n",
    "shallow_noiseless = data_noiseless[-pd.DataFrame(data_all[:, 0::2]).isna()[0]]\n",
    "shallow_err = np.tile(data_all[0, 1::2],  (shallow_data.shape[0], 1))\n",
    "\n",
    "deep_data = pd.DataFrame(data_deep[:, 0::2]).dropna().to_numpy()\n",
    "deep_info = df_L3_info[-pd.DataFrame(data_deep[:, 0::2]).isna()[0]]\n",
    "deep_noiseless = data_noiseless[-pd.DataFrame(data_deep[:, 0::2]).isna()[0]]\n",
    "deep_err = np.tile(data_deep[0, 1::2],  (deep_data.shape[0], 1))\n",
    "\n",
    "noiseless_info = df_L3_info[-pd.DataFrame(data_noiseless).isna()[0]]\n",
    "noiseless_data = pd.DataFrame(data_noiseless).dropna()\n",
    "noiseless_info = noiseless_info[-noiseless_data[noiseless_data > 0].isna()[0]]\n",
    "noiseless_data = noiseless_data[noiseless_data > 0].dropna().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2938729d-f6f6-4d9c-94c8-081ae87c2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(data, err, info_data, file):\n",
    "    skip = False\n",
    "    try:\n",
    "        with open(file, \"rb\") as fh:\n",
    "            record = pickle.load(fh)\n",
    "    except:\n",
    "        print(file)\n",
    "        skip = True\n",
    "\n",
    "    if skip == False:\n",
    "        som = record[\"som\"]\n",
    "        \n",
    "        if \"b_scale\" in record:\n",
    "            b_scale = record[\"b_scale\"]\n",
    "        else:\n",
    "            b_scale = 1.042\n",
    "            \n",
    "        dim = record[\"dim\"] \n",
    "        lupmag = -np.arcsinh(data / (2 * b_scale  * err))\n",
    "        proc_data = (lupmag - np.mean(lupmag, axis=0)) / np.std(lupmag, ddof = 1, axis=0)\n",
    "    \n",
    "        if True:\n",
    "            if np.absolute(som.topographic_error(proc_data) - record[\"topo_err\"]) < 10 ** (-5) and np.absolute(som.quantization_error(proc_data) - record[\"quan_err\"]) < 10 ** (-5):\n",
    "                proc_err = np.absolute(-1 / (2 * b_scale  * err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "                proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "                labels_map = som.labels_map(proc_data, proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                                  np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                                  np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "                record[\"prop_map\"] = labels_map\n",
    "                \n",
    "                z_std_gal = np.array([])\n",
    "                labels_map = record[\"prop_map\"]\n",
    "                \n",
    "                for i in labels_map.keys():\n",
    "                    properties = np.array(list(labels_map[i].keys()))\n",
    "                    means = np.mean(properties, axis = 0)\n",
    "                    stds = np.std(properties, axis = 0, ddof = 1)\n",
    "                    z_std_gal = np.concatenate((z_std_gal, np.tile(np.array(stds[1] / (means[1] + 1)), properties.shape[0])))\n",
    "                    \n",
    "                record[\"z_std_gal\"] = z_std_gal\n",
    "                record[\"mean_z_std\"] = np.nanmean(z_std_gal)\n",
    "            \n",
    "                try:\n",
    "                    with open(file, 'wb') as fh:\n",
    "                        pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                except KeyboardInterrupt:\n",
    "                    print('KeyboardInterrupt caught, data saved.')\n",
    "            else:\n",
    "                print(\"Wrong data\")\n",
    "        else:\n",
    "            if len(list(list(record[\"prop_map\"].items())[0][1].keys())[0]) != 3 or \"prop_map\" not in record:\n",
    "                if np.absolute(som.topographic_error(proc_data) - record[\"topo_err\"]) < 10 ** (-5) and np.absolute(som.quantization_error(proc_data) - record[\"quan_err\"]) < 10 ** (-5):\n",
    "                    proc_err = np.absolute(-1 / (2 * b_scale  * err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "                    proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "                    labels_map = som.labels_map(proc_data, proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                                      np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                                      np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "                    record[\"prop_map\"] = labels_map\n",
    "                    \n",
    "                    z_std_gal = np.array([])\n",
    "                    labels_map = record[\"prop_map\"]\n",
    "                    \n",
    "                    for i in labels_map.keys():\n",
    "                        properties = np.array(list(labels_map[i].keys()))\n",
    "                        means = np.mean(properties, axis = 0)\n",
    "                        stds = np.std(properties, axis = 0, ddof = 1)\n",
    "                        z_std_gal = np.concatenate((z_std_gal, np.tile(np.array(stds[1] / (means[1] + 1)), properties.shape[0])))\n",
    "                        \n",
    "                    record[\"z_std_gal\"] = z_std_gal\n",
    "                    record[\"mean_z_std\"] = np.nanmean(z_std_gal)\n",
    "                \n",
    "                    try:\n",
    "                        with open(file, 'wb') as fh:\n",
    "                            pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    except KeyboardInterrupt:\n",
    "                        print('KeyboardInterrupt caught, data saved.')\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Wrong data\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bcb5377f-ca65-4e0c-b100-72a78a3b1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map_mag(data, err, info_data, file):\n",
    "    skip = False\n",
    "    try:\n",
    "        with open(file, \"rb\") as fh:\n",
    "            record = pickle.load(fh)\n",
    "    except:\n",
    "        print(file)\n",
    "        skip = True\n",
    "\n",
    "    if skip == False:\n",
    "        som = record[\"som\"]\n",
    "        dim = record[\"dim\"] \n",
    "        proc_data = -2.5 * np.log10(data / 10 ** 6) + 8.9\n",
    "        proc_data = (proc_data - np.mean(proc_data, axis=0)) / np.std(proc_data, ddof = 1, axis=0)\n",
    "        if \"prop_map\" not in record:\n",
    "            if np.absolute(som.topographic_error(proc_data) - record[\"topo_err\"]) < 10 ** (-5) and np.absolute(som.quantization_error(proc_data) - record[\"quan_err\"]) < 10 ** (-5):\n",
    "                labels_map = som.labels_map(proc_data, err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                                  np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                                  np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "                record[\"prop_map\"] = labels_map\n",
    "                \n",
    "                z_std_gal = np.array([])\n",
    "                labels_map = record[\"prop_map\"]\n",
    "                \n",
    "                for i in labels_map.keys():\n",
    "                    properties = np.array(list(labels_map[i].keys()))\n",
    "                    means = np.mean(properties, axis = 0)\n",
    "                    stds = np.std(properties, axis = 0, ddof = 1)\n",
    "                    z_std_gal = np.concatenate((z_std_gal, np.tile(np.array(stds[1] / (means[1] + 1)), properties.shape[0])))\n",
    "                    \n",
    "                record[\"z_std_gal\"] = z_std_gal\n",
    "                record[\"mean_z_std\"] = np.nanmean(z_std_gal)\n",
    "            \n",
    "                try:\n",
    "                    with open(file, 'wb') as fh:\n",
    "                        pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                except KeyboardInterrupt:\n",
    "                    print('KeyboardInterrupt caught, data saved.')\n",
    "            else:\n",
    "                print(\"Wrong data\")\n",
    "        else:\n",
    "            if len(list(list(record[\"prop_map\"].items())[0][1].keys())[0]) != 3 or \"prop_map\" not in record:\n",
    "                if np.absolute(som.topographic_error(proc_data) - record[\"topo_err\"]) < 10 ** (-5) and np.absolute(som.quantization_error(proc_data) - record[\"quan_err\"]) < 10 ** (-5):\n",
    "                    labels_map = som.labels_map(proc_data, err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                                      np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                                      np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "                    record[\"prop_map\"] = labels_map\n",
    "                    \n",
    "                    z_std_gal = np.array([])\n",
    "                    labels_map = record[\"prop_map\"]\n",
    "                    \n",
    "                    for i in labels_map.keys():\n",
    "                        properties = np.array(list(labels_map[i].keys()))\n",
    "                        means = np.mean(properties, axis = 0)\n",
    "                        stds = np.std(properties, axis = 0, ddof = 1)\n",
    "                        z_std_gal = np.concatenate((z_std_gal, np.tile(np.array(stds[1] / (means[1] + 1)), properties.shape[0])))\n",
    "                        \n",
    "                    record[\"z_std_gal\"] = z_std_gal\n",
    "                    record[\"mean_z_std\"] = np.nanmean(z_std_gal)\n",
    "                \n",
    "                    try:\n",
    "                        with open(file, 'wb') as fh:\n",
    "                            pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    except KeyboardInterrupt:\n",
    "                        print('KeyboardInterrupt caught, data saved.')\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Wrong data\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "722c6757-2d40-45ef-90e1-77cd089e9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_std(names, means, n = 5):\n",
    "    best_means = []\n",
    "    best_names = []\n",
    "    for i in range(0, n):\n",
    "        best_means.append(np.min(means))\n",
    "        best_names.append(names[np.argmin(means)])\n",
    "        names = names[means > np.min(means)]\n",
    "        means = means[means > np.min(means)]\n",
    "        \n",
    "    return best_means, best_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "270821e0-5153-4d49-9e38-404093bcdfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\")\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_shallow_30\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            del record[\"b_scale\"]\n",
    "            # try:\n",
    "            #     with open(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\" + i, 'wb') as fh:\n",
    "            #         pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            # except KeyboardInterrupt:\n",
    "            #     print('KeyboardInterrupt caught, data saved.')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fe99e-8db6-4893-b1d3-5aff46a8c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\")\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_shallow_30\" in i:\n",
    "        label_map(data = shallow_data, err = shallow_err, info_data = shallow_info, file = \"D:/SPHEREx_SOM/record/4th_exploration/SOM/\" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6e8224db-ccae-4552-ae96-010ffb815dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\")\n",
    "means30shallow = []\n",
    "names30shallow = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_shallow_30\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means30shallow.append(record[\"mean_z_std\"])\n",
    "                names30shallow.append(i)\n",
    "        except:\n",
    "            pass\n",
    "means30shallow = np.array(means30shallow)\n",
    "names30shallow = np.array(names30shallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8e8502a2-9dc7-48c4-ba41-e755c17dbfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\")\n",
    "means30deep = []\n",
    "names30deep = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_deep_30\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/4th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means30deep.append(record[\"mean_z_std\"])\n",
    "                names30deep.append(i)\n",
    "        except:\n",
    "            pass\n",
    "means50deep = np.array(means50deep)\n",
    "names50deep = np.array(names50deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7312b551-4798-488f-b2ed-027a1d3bfed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/5th_exploration/SOM/\")\n",
    "means50shallow = []\n",
    "names50shallow = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_shallow_50\" in i and \"20\" not in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/5th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means50shallow.append(record[\"mean_z_std\"])\n",
    "                names50shallow.append(i)\n",
    "        except:\n",
    "            pass\n",
    "means50shallow = np.array(means50shallow)\n",
    "names50shallow = np.array(names50shallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32193b14-5f79-4903-ad2d-694813d73106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/5th_exploration/SOM/\")\n",
    "means50deep = []\n",
    "names50deep = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_deep_50\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/5th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means50deep.append(record[\"mean_z_std\"])\n",
    "                names50deep.append(i)\n",
    "        except:\n",
    "            pass\n",
    "means50deep = np.array(means50deep)\n",
    "names50deep = np.array(names50deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "571fc4ca-42e1-4685-b169-e95c7003c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/6th_exploration/SOM/\")\n",
    "means70deep = []\n",
    "names70deep = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_deep_70\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/6th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means70deep.append(record[\"mean_z_std\"])\n",
    "                names70deep.append(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "means70deep = np.array(means70deep)\n",
    "names70deep = np.array(names70deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "23d7206a-2b73-426f-a9dd-ac5ecd050a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%%\r"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"D:/SPHEREx_SOM/record/6th_exploration/SOM/\")\n",
    "means70shallow = []\n",
    "names70shallow = []\n",
    "n = 0\n",
    "for i in files:\n",
    "    n += 1\n",
    "    print(f\"{round(n / len(files) * 100, 3) }%\", end = \"\\r\")\n",
    "    if \"lup_shallow_70\" in i:\n",
    "        try:\n",
    "            with open(\"D:/SPHEREx_SOM/record/6th_exploration/SOM/\" + i, \"rb\") as fh:\n",
    "                record = pickle.load(fh)\n",
    "            if \"mean_z_std\" in record:\n",
    "                means70shallow.append(record[\"mean_z_std\"])\n",
    "                names70shallow.append(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "means70shallow = np.array(means70shallow)\n",
    "names70shallow = np.array(names70shallow)\n",
    "names70shallow = names70shallow[means70shallow > 0.13]\n",
    "means70shallow = means70shallow[means70shallow > 0.13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ae31af87-5dca-44f8-8d9e-f90145860de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11670291420469942\n",
      "0.09753727190299434\n",
      "0.08651051593538707\n"
     ]
    }
   ],
   "source": [
    "print(np.min(means30deep))\n",
    "print(np.min(means50deep))\n",
    "print(np.min(means70deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f86556ec-2fc0-4903-9d8b-ef0b649493d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_lup_deep_30_0.7_0.112_2.pkl\n",
      "chi2_lup_deep_50_0.9_0.4_10_8.pkl\n",
      "chi2_lup_deep_70_1.1_1.1500000000000004_7_10.pkl\n"
     ]
    }
   ],
   "source": [
    "print(names30deep[np.argmin(means30deep)])\n",
    "print(names50deep[np.argmin(means50deep)])\n",
    "print(names70deep[np.argmin(means70deep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "43331895-0f73-4815-999f-bb3a3f47b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16333414270143426\n",
      "0.1557392826995994\n",
      "0.14714224449843774\n"
     ]
    }
   ],
   "source": [
    "print(np.min(means30shallow))\n",
    "print(np.min(means50shallow))\n",
    "print(np.min(means70shallow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "348f57f1-f59d-4642-aafe-9e461a0697eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_lup_shallow_30_1.6_0.02_1000_2.pkl\n",
      "chi2_lup_shallow_50_1.8_0.15_1000_10.pkl\n",
      "chi2_lup_shallow_70_3.0_0.2_9_1000.pkl\n"
     ]
    }
   ],
   "source": [
    "print(names30shallow[np.argmin(means30shallow)])\n",
    "print(names50shallow[np.argmin(means50shallow)])\n",
    "print(names70shallow[np.argmin(means70shallow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "50a8bf39-7cbd-4cd8-aa7d-5eeaf6184939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.14714224449843774),\n",
       "  np.float64(0.1474401795761474),\n",
       "  np.float64(0.14755486028834508),\n",
       "  np.float64(0.1476456534258754),\n",
       "  np.float64(0.14771782321299337),\n",
       "  np.float64(0.14774044221769944),\n",
       "  np.float64(0.14829741729057672),\n",
       "  np.float64(0.1483199716656326),\n",
       "  np.float64(0.1484160280066544),\n",
       "  np.float64(0.1485132694997687)],\n",
       " [np.str_('chi2_lup_shallow_70_3.0_0.2_9_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_2.6_0.25_6_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_2.6_0.25_5_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_3.0_0.2_8_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_2.6_0.25_10_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_2.6_0.25_8_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_3.0_0.2_7_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_1.7_0.45_10_100.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_3.0_0.2_5_1000.pkl'),\n",
       "  np.str_('chi2_lup_shallow_70_2.6_0.25_7_1000.pkl')])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_std(names = names70shallow, means = means70shallow, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "14ea2d3f-03ca-4ad9-b09d-2ce140a98c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.08651051593538707),\n",
       "  np.float64(0.0865135717925882),\n",
       "  np.float64(0.08657592544638155),\n",
       "  np.float64(0.08671415560663555),\n",
       "  np.float64(0.08705014141707373),\n",
       "  np.float64(0.0870682024314059),\n",
       "  np.float64(0.08715527827370809),\n",
       "  np.float64(0.0871632220112652),\n",
       "  np.float64(0.08728962897161734),\n",
       "  np.float64(0.08729257115339313)],\n",
       " [np.str_('chi2_lup_deep_70_1.1_1.1500000000000004_7_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.3_1_7_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.9749999999999999_0.34_6_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.5_0.667_6_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.525_0.617_6_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.925_0.54_6_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.3_1_6_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.125_0.9000000000000001_7_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_2.1_0.54_9_10.pkl'),\n",
       "  np.str_('chi2_lup_deep_70_1.5499999999999998_0.7170000000000001_6_10.pkl')])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_std(names = names70deep, means = means70deep, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd18dc-0a01-4115-b488-72791464f941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
