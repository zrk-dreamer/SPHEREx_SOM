{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1b3cc3-e5de-40d1-b672-e569faff611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from minisom import MiniSom\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7875d2-65b5-4a64-9c97-2fce0fceea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_L3_info = Table.read('../dataset/L3_COSMOS2020_Richard_RefCat_2023DEC4_info.fits')\n",
    "df_L3_info = df_L3_info.to_pandas().sort_values(by = \"cosmos_id\")\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/Noiseless_phot_cosmos_nolines_refcat30k.txt'\n",
    "data_noiseless = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/NoisySphx_shallow_nolines_refcat30k.txt'\n",
    "data_all = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/NoisySphx_deep_nolines_refcat30k.txt'\n",
    "data_deep = np.loadtxt(fname)[:, 3:]\n",
    "\n",
    "fname = 'D:/SPHEREx_SOM/dataset/sphx_refcat/SPHEREx_1sigma_noise.txt'\n",
    "data_1sig  = np.loadtxt(fname, skiprows=1)\n",
    "wl = data_1sig[:,0]\n",
    "sigma_all = data_1sig[:,1]\n",
    "sigma_deep = data_1sig[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d679bffe-3562-4dcc-8f21-3d209da91f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_visual(file, save_diagram, mode, figure_size = 20):\n",
    "    with open(file, \"rb\") as fh:\n",
    "        record = pickle.load(fh)\n",
    "        \n",
    "    labels_map = record[\"prop_map\"]\n",
    "    data_type = record[\"type\"]\n",
    "    dim = record[\"dim\"]\n",
    "    sigma = record[\"sigma\"]\n",
    "    rate = record[\"rate\"]\n",
    "    iteration = record[\"iter\"]\n",
    "    b_scale = record[\"b_scale\"]\n",
    "    z_std_gal = record[\"z_std_gal\"]\n",
    "    som = record[\"som\"]\n",
    "\n",
    "    density_map = np.zeros(dim ** 2).reshape(dim, dim)\n",
    "    magnitude_map = np.zeros(dim ** 2).reshape(dim, dim)\n",
    "    magnitude_map.fill(np.nan)\n",
    "    z_map = np.zeros(dim ** 2).reshape(dim, dim)\n",
    "    z_map.fill(np.nan)\n",
    "    \n",
    "    for i in labels_map.keys():\n",
    "        properties = np.array(list(labels_map[i].keys()))\n",
    "        means = np.mean(properties, axis = 0)\n",
    "        medians = np.median(properties, axis = 0)\n",
    "        stds = np.nanstd(properties, axis = 0, ddof = 1)\n",
    "        density_map[int(list(i)[0]), int(list(i)[1])] = len(properties)\n",
    "        if mode == \"median\":\n",
    "            magnitude_map[int(list(i)[0]), int(list(i)[1])] = medians[0]\n",
    "            z_map[int(list(i)[0]), int(list(i)[1])] = medians[1]\n",
    "        else:\n",
    "            magnitude_map[int(list(i)[0]), int(list(i)[1])] = means[0]\n",
    "            z_map[int(list(i)[0]), int(list(i)[1])] = means[1]\n",
    "\n",
    "    print(f\"Mean z std: {round(np.nanmean(z_std_gal), 5)}\")\n",
    "        \n",
    "    %matplotlib inline\n",
    "    plt.close()\n",
    "    plt.figure(figsize = (figure_size * 1.618, figure_size))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.pcolor(som.distance_map().T, cmap='YlGn') \n",
    "    plt.colorbar()\n",
    "    plt.title(\"Distance map (U-matrix)\")\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.pcolor(density_map.T, cmap='YlGn')\n",
    "    plt.colorbar().set_label(\"# galaxies\")\n",
    "    plt.title(\"Density Map\")\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.pcolor(magnitude_map.T, cmap=\"plasma\" + \"_r\")\n",
    "    plt.colorbar().set_label(\"Median HSC i-band AB magnitude\")\n",
    "    plt.title(\"HSC i-band AB Magnitude\")\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.pcolor(z_map.T, cmap=\"plasma\")\n",
    "    plt.colorbar().set_label(\"Median True Redshift\")\n",
    "    plt.title(\"True Redshift\")\n",
    "    plt.subplots_adjust(hspace = 0., wspace = 0)\n",
    "\n",
    "    if  save_diagram:\n",
    "        plt.savefig(f\"D:/SPHEREx_SOM/record/6th_exploration/basic_visual/{data_type}_{dim}_{float(sigma)}_{float(rate)}_{iteration}_{b_scale}.jpg\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f81d97e9-74bb-4375-99c1-2fedaaf3e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_cell(data, err, info_data, file, save_diagram, position, noiseless_data, wave = data_1sig[:, 0]):\n",
    "    with open(file, \"rb\") as fh:\n",
    "        record = pickle.load(fh)\n",
    "\n",
    "    som = record[\"som\"]\n",
    "    b_scale = record[\"b_scale\"]\n",
    "    dim = record[\"dim\"] \n",
    "    lupmag = -np.arcsinh(data / (2 * b_scale  * err))\n",
    "    proc_data = (lupmag - np.mean(lupmag, axis=0)) / np.std(lupmag, ddof = 1, axis=0)\n",
    "    \n",
    "    if len(list(list(record[\"prop_map\"].items())[0][1].keys())[0]) != 3:\n",
    "        proc_err = np.absolute(-1 / (2 * b_scale  * err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "        proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "    \n",
    "        print(f\"Topological error: {som.topographic_error(proc_data)}\")\n",
    "        print(f\"Quantization error: {som.quantization_error(proc_data)}\")\n",
    "        print(f\"Topological error: {record[\"topo_err\"]}\")\n",
    "        print(f\"Quantization error: {record[\"quan_err\"]}\")\n",
    "        \n",
    "        labels_map = som.labels_map(proc_data, proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                          np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                          np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "        record[\"prop_map\"] = labels_map\n",
    "        \n",
    "        try:\n",
    "            with open(file, 'wb') as fh:\n",
    "                pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt caught, data saved.')\n",
    "    else:\n",
    "        labels_map = record[\"prop_map\"]\n",
    "\n",
    "    skip = True\n",
    "    for i in labels_map.keys():\n",
    "        if i == position:\n",
    "            properties = np.array(list(labels_map[position].keys()))\n",
    "            z_min = np.min(properties[:, 1])\n",
    "            z_max = np.max(properties[:, 1])\n",
    "            skip = False\n",
    "            break\n",
    "            \n",
    "    if not skip:\n",
    "        plt.close()\n",
    "        plt.figure(figsize = (30, 10))\n",
    "        plt.subplot(121)\n",
    "        plt.hist(properties[:,0], bins = 30, range = (np.min(info_data[\"HSC_i_MAG\"]), np.max(info_data[\"HSC_i_MAG\"])), density = True, alpha = 0.6, color='#1abc9c')\n",
    "        plt.xlabel(\"HSC i-band Magitude\")\n",
    "        plt.ylabel(\"# of Galaxies\")\n",
    "        plt.title(f\"Mean: {round(np.mean(properties[:,0]), 5)} Median: {round(np.median(properties[:, 0]), 5)} Std: {round(np.std(properties[:, 0], ddof = 1) / (1 + np.mean(properties[:, 0])), 5)} Total: {len(properties[:,0])}\")\n",
    "        plt.axvline(x = np.mean(properties[:,0]), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.median(properties[:,0]), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "    \n",
    "        plt.subplot(122)\n",
    "        plt.hist(properties[:,1], bins = 30, range = (np.min(info_data[\"z_true\"]), np.max(info_data[\"z_true\"])), density = True, alpha = 0.6, color='#1abc9c')\n",
    "        if properties[:,1].shape[0] > 1:\n",
    "            density = gaussian_kde(properties[:,1])\n",
    "            z_range = np.linspace(np.min(info_data[\"z_true\"]), np.max(info_data[\"z_true\"]), 1000)\n",
    "            pdf = density(z_range)\n",
    "            plt.plot(z_range, pdf, lw = 2, c = '#9b59b6')\n",
    "        plt.xlabel(\"Spectroscopic Redshift\")\n",
    "        plt.ylabel(\"Probability Density Function\")\n",
    "        plt.title(f\"Mean: {round(np.mean(properties[:,1]), 5)} Median: {round(np.median(properties[:, 1]), 5)} Std: {round(np.std(properties[:,1 ], ddof = 1) / (1 + np.mean(properties[:, 1])), 5)} Total: {len(properties[:,0])}\")\n",
    "        plt.axvline(x = np.mean(properties[:,1]), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.median(properties[:,1]), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "        if save_diagram != False:\n",
    "            plt.savefig(\"D:/SPHEREx_SOM/record/6th_exploration/in_cell/\" + file.split(\"/\")[-1].replace(\".pkl\", \"\") + \"_\" + str(position) + \"_\" + \"hist.jpg\", bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize = (30, 20))\n",
    "        colormap = plt.cm.rainbow\n",
    "        plt.subplot(211)\n",
    "        for i in properties:\n",
    "            plt.plot(wave, noiseless_data[i[2].astype(np.int32)] / 1000, marker = \".\", alpha = 0.3, color = colormap((i[1] - z_min) / (z_max - z_min)))\n",
    "        plt.plot(wave, np.mean(noiseless_data[properties[:, 2].astype(np.int32)] / 1000, axis = 0), marker = \".\", lw = 4, c = \"k\", label = \"Mean\", ls = \"--\")\n",
    "        plt.xlabel(\"Wavelength (micrometer)\")\n",
    "        plt.ylabel(\"Flux Density (mJy)\")\n",
    "        plt.ylim(np.min(np.min(data[properties[:, 2].astype(np.int32)]) * 1.1, 0), np.max(data[properties[:, 2].astype(np.int32)]) * 1.05)\n",
    "        plt.title(\"Noiseless data\")\n",
    "        plt.legend()\n",
    "    \n",
    "        weights = som.get_weights()\n",
    "    \n",
    "        plt.subplot(212)\n",
    "        for i in properties:\n",
    "            plt.plot(wave, data[i[2].astype(np.int32)], marker = \".\", alpha = 0.3, color = colormap((i[1] - z_min) / (z_max - z_min)))\n",
    "        plt.plot(wave, np.mean(data[properties[:, 2].astype(np.int32)], axis = 0), marker = \".\", lw = 3, c = \"k\", label = \"Mean\", ls = \"--\")\n",
    "        plt.plot(wave, np.sinh(-((weights[position[0], position[1]]) * np.std(lupmag, ddof = 1, axis=0) + np.mean(lupmag, axis=0))) * (2 * b_scale  * err[0]), marker = \".\", lw = 3, c = \"r\", label = \"Weight\", ls = \"--\")\n",
    "        plt.xlabel(\"Wavelength (micrometer)\")\n",
    "        plt.ylabel(\"Flux Density (mJy)\")\n",
    "        plt.ylim(np.min(np.min(data[properties[:, 2].astype(np.int32)]) * 1.1, 0), np.max(data[properties[:, 2].astype(np.int32)]) * 1.05)\n",
    "        plt.title(\"Noisy data\")\n",
    "        plt.legend()\n",
    "        if save_diagram != False:\n",
    "            plt.savefig(\"D:/SPHEREx_SOM/record/6th_exploration/in_cell/\" + file.split(\"/\")[-1].replace(\".pkl\", \"\") + \"_\" + str(position) + \"_\" + \"photo.jpg\", bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        return np.sinh(-((weights[position[0], position[1]]) * np.std(lupmag, ddof = 1, axis=0) + np.mean(lupmag, axis=0))) * (2 * b_scale  * err[0])\n",
    "    else:\n",
    "        print(\"No data in this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "517f34a8-0b5f-457c-b2d9-7e0b8068a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_map(data, err, info_data, file, save_diagram):\n",
    "    with open(file, \"rb\") as fh:\n",
    "        record = pickle.load(fh)\n",
    "    dim = record[\"dim\"]\n",
    "    som = record[\"som\"]\n",
    "    b_scale = 1000\n",
    "        \n",
    "    lupmag = -np.arcsinh(data / (2 * b_scale  * err))\n",
    "    proc_err = np.absolute(-1 / (2 * b_scale  * err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "    \n",
    "    proc_data = (lupmag- np.mean(lupmag, axis=0)) / np.std(lupmag, ddof = 1, axis=0)\n",
    "    proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "\n",
    "    mag_std = np.zeros(dim ** 2).reshape(dim, dim)\n",
    "    mag_std.fill(np.nan)\n",
    "    z_std = np.zeros(dim ** 2).reshape(dim, dim)\n",
    "    z_std.fill(np.nan)\n",
    "\n",
    "    mag_std_gal = np.array([])\n",
    "    z_std_gal = np.array([])\n",
    "    \n",
    "    print(f\"Topological error: {som.topographic_error(proc_data)}\")\n",
    "    print(f\"Quantization error: {som.quantization_error(proc_data)}\")\n",
    "    print(f\"Topological error: {record[\"topo_err\"]}\")\n",
    "    print(f\"Quantization error: {record[\"quan_err\"]}\")\n",
    "\n",
    "    if \"prop_map\" not in record:\n",
    "        labels_map = som.labels_map(proc_data, proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), np.expand_dims(info_data[\"z_true\"].values, axis = 1), np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "    \n",
    "        for i in labels_map.keys():\n",
    "            properties = np.array(list(labels_map[i].keys()))\n",
    "            means = np.mean(properties, axis = 0)\n",
    "            stds = np.std(properties, axis = 0, ddof = 1)\n",
    "            mag_std[int(list(i)[0]), int(list(i)[1])] = stds[0]\n",
    "            z_std[int(list(i)[0]), int(list(i)[1])] = stds[1] / (means[1] + 1)\n",
    "            mag_std_gal = np.concatenate((mag_std_gal, np.tile(np.array([stds[0]]), properties.shape[0])))\n",
    "            z_std_gal = np.concatenate((z_std_gal, np.tile(np.array(stds[1] / (means[1] + 1)), properties.shape[0])))\n",
    "\n",
    "        print(np.nanmean(z_std_gal))\n",
    "\n",
    "        %matplotlib inline\n",
    "        plt.close()\n",
    "        plt.figure(figsize = (30, 20))\n",
    "        plt.subplot(221)\n",
    "        plt.pcolor(mag_std.T, cmap='YlGn') \n",
    "        plt.colorbar()\n",
    "        plt.title(\"HSC i-band std\")\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.pcolor(z_std.T, cmap='YlGn') \n",
    "        plt.colorbar()\n",
    "        plt.title(\"Redshift std\")\n",
    "\n",
    "        plt.subplot(223)\n",
    "        plt.hist(mag_std_gal, bins = 50, alpha = 0.6, color='#1abc9c')\n",
    "        plt.axvline(x = np.nanmean(mag_std_gal), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.nanmedian(mag_std_gal), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "        plt.title(\"HSC i-band STD Histogram\")\n",
    "        \n",
    "        plt.subplot(224)\n",
    "        plt.hist(z_std_gal, bins = 50, alpha = 0.6, color='#1abc9c')\n",
    "        plt.axvline(x = np.nanmean(z_std_gal), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.nanmedian(z_std_gal), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "        plt.title(\"Redshift STD Histogram\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        record[\"prop_map\"] = labels_map\n",
    "        \n",
    "        try:\n",
    "            with open(file, 'wb') as fh:\n",
    "                pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt caught, data saved.')\n",
    "    else:\n",
    "        labels_map = record[\"prop_map\"]\n",
    "        \n",
    "        for i in labels_map.keys():\n",
    "            properties = np.array(list(labels_map[i].keys()))\n",
    "            means = np.mean(properties, axis = 0)\n",
    "            stds = np.std(properties, axis = 0, ddof = 1)\n",
    "            mag_std[int(list(i)[0]), int(list(i)[1])] = stds[0]\n",
    "            z_std[int(list(i)[0]), int(list(i)[1])] = stds[1] / (means[1] + 1)\n",
    "            mag_std_gal = np.concatenate((mag_std_gal, np.tile(np.array([stds[0]]), properties.shape[0])))\n",
    "            z_std_gal = np.concatenate((z_std_gal, np.tile(np.array([stds[1] / (means[1] + 1)]), properties.shape[0])))\n",
    "\n",
    "        print(f\"Mean redshift std: {np.nanmean(z_std_gal)}\")\n",
    "        print(f\"std < 0.003: {z_std_gal[z_std_gal < 0.003].shape[0] * 30000 / 2 / 10 ** 6}\")\n",
    "        print(f\"std < 0.01: {z_std_gal[z_std_gal < 0.01].shape[0] * 30000 / 2 / 10 ** 6}\")\n",
    "        print(f\"std < 0.03: {z_std_gal[z_std_gal < 0.03].shape[0] * 30000 / 2 / 10 ** 6}\")\n",
    "        print(f\"std < 0.1: {z_std_gal[z_std_gal < 0.1].shape[0] * 30000 / 2 / 10 ** 6}\")\n",
    "        print(f\"std < 0.2: {z_std_gal[z_std_gal < 0.2].shape[0] * 30000 / 2 / 10 ** 6}\")\n",
    "\n",
    "        %matplotlib inline\n",
    "        plt.close()\n",
    "        plt.figure(figsize = (30, 20))\n",
    "        plt.subplot(221)\n",
    "        plt.pcolor(mag_std.T, cmap='YlGn') \n",
    "        plt.colorbar().set_label(r'$\\sigma_{i-band}$')\n",
    "        plt.title(r\"$\\sigma_{i-band}$\")\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.pcolor(z_std.T, cmap='YlGn') \n",
    "        plt.colorbar().set_label(r\"$\\sigma_z / (1+<z>)$\")\n",
    "        plt.title(r\"$\\sigma_z / (1+<z>)$\")\n",
    "\n",
    "        plt.subplot(223)\n",
    "        plt.hist(mag_std_gal, bins = 50, alpha = 0.6, color='#1abc9c')\n",
    "        plt.axvline(x = np.nanmean(mag_std_gal), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.nanmedian(mag_std_gal), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "        plt.title(\"HSC i-band STD Histogram\")\n",
    "        plt.xlabel(r\"$\\sigma_{i-band}$\")\n",
    "        plt.ylabel(\"# of galaxies\")\n",
    "        \n",
    "        plt.subplot(224)\n",
    "        plt.hist(z_std_gal, bins = 50, alpha = 0.6, color='#1abc9c')\n",
    "        plt.axvline(x = np.nanmean(z_std_gal), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "        plt.axvline(x = np.nanmedian(z_std_gal), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "        plt.legend()\n",
    "        plt.title(\"Redshift STD Histogram\")\n",
    "        plt.xlabel(r\"$\\sigma_z / (1+<z>)$\")\n",
    "        plt.ylabel(\"# of galaxies\")\n",
    "        if save_diagram != False:\n",
    "            plt.savefig(\"D:/SPHEREx_SOM/record/4th_exploration/std_map/\" + file.split(\"/\")[-1].replace(\".pkl\", \"\") + \"_\" + \"std_map.jpg\", bbox_inches = \"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4378188a-209f-4d3a-8910-c3cc8bc75057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(shallow_file, deep_file, shallow_data, deep_data, shallow_err, deep_err, shallow_position, info_data, save_diagram = False):\n",
    "    def luptitude(data, err, b_scale):\n",
    "        lupmag = -np.arcsinh(data / (2 * b_scale  * err))\n",
    "        proc_err = np.absolute(-1 / (2 * b_scale  * shallow_err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "        proc_data = (lupmag- np.mean(lupmag, axis=0)) / np.std(lupmag, ddof = 1, axis=0)\n",
    "        proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "\n",
    "        return proc_data, proc_err\n",
    "        \n",
    "    with open(shallow_file, \"rb\") as fh:\n",
    "        shallow = pickle.load(fh)\n",
    "\n",
    "    with open(deep_file, \"rb\") as fh:\n",
    "        deep = pickle.load(fh)\n",
    "        \n",
    "    shallow_som = shallow[\"som\"]\n",
    "    deep_som = deep[\"som\"]\n",
    "    \n",
    "    dim = shallow[\"dim\"]\n",
    "    \n",
    "    shallow_b_scale = shallow[\"b_scale\"]\n",
    "    deep_b_scale = deep[\"b_scale\"]\n",
    "    \n",
    "    shallow_proc_data, shallow_proc_err = luptitude(data = shallow_data, err = shallow_err, b_scale = shallow_b_scale )\n",
    "    deep_proc_data, deep_proc_err = luptitude(data = deep_data, err = deep_err, b_scale = deep_b_scale )\n",
    "    \n",
    "    print(f\"Topo err: {shallow_som.topographic_error(shallow_proc_data)}\")\n",
    "    print(f\"Quan err: {shallow_som.quantization_error(shallow_proc_data)}\")\n",
    "    print(f\"Topo err: {shallow[\"topo_err\"]}\")\n",
    "    print(f\"Quan err: {shallow[\"quan_err\"]}\")\n",
    "\n",
    "    print(f\"Topo err: {deep_som.topographic_error(deep_proc_data)}\")\n",
    "    print(f\"Quan err: {deep_som.quantization_error(deep_proc_data)}\")\n",
    "    print(f\"Topo err: {deep[\"topo_err\"]}\")\n",
    "    print(f\"Quan err: {deep[\"quan_err\"]}\")\n",
    "\n",
    "    if len(list(list(shallow[\"prop_map\"].items())[0][1].keys())[0]) != 3:\n",
    "        shallow_labels_map = shallow_som.labels_map(shallow_proc_data, shallow_proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), np.expand_dims(info_data[\"z_true\"].values, axis = 1), np.expand_dims(np.array([i for i in range(0, shallow_proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "        shallow[\"prop_map\"] = shallow_labels_map\n",
    "        \n",
    "        try:\n",
    "            with open(shallow_file, 'wb') as fh:\n",
    "                pickle.dump(shallow, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt caught, data saved.')\n",
    "    else:\n",
    "        shallow_labels_map = shallow[\"prop_map\"]\n",
    "\n",
    "    if len(list(list(deep[\"prop_map\"].items())[0][1].keys())[0]) != 3:\n",
    "        deep_labels_map = deep_som.labels_map(deep_proc_data, deep_proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), np.expand_dims(info_data[\"z_true\"].values, axis = 1), np.expand_dims(np.array([i for i in range(0, deep_proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "        deep[\"prop_map\"] = deep_labels_map\n",
    "        \n",
    "        try:\n",
    "            with open(deep_file, 'wb') as fh:\n",
    "                pickle.dump(deep, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt caught, data saved.')\n",
    "    else:\n",
    "        deep_labels_map = deep[\"prop_map\"]\n",
    "\n",
    "    z_range = np.linspace(np.min(info_data[\"z_true\"]), np.max(info_data[\"z_true\"]), 1000)\n",
    "    \n",
    "    for i in shallow_labels_map.keys():\n",
    "        if i == shallow_position:\n",
    "            shallow_properties = np.array(list(shallow_labels_map[shallow_position].keys()))\n",
    "            indices = shallow_properties[:, 2].astype(np.int32)\n",
    "            shallow_density = gaussian_kde(shallow_properties[:, 1])\n",
    "\n",
    "    mapped_cells = []\n",
    "    for i in indices:\n",
    "        mapped_cells.append(deep_som.winner(deep_proc_data[i], deep_proc_err[i]))\n",
    "\n",
    "    deep_position, counts = np.unique(np.array(mapped_cells), return_counts = True, axis = 0)\n",
    "    \n",
    "    deep_pdfs = []\n",
    "    for i in range(0, len(deep_position)):\n",
    "        deep_properties = np.array(list(deep_labels_map[tuple(deep_position[i])].keys()))\n",
    "        deep_density = gaussian_kde(deep_properties[:, 1])\n",
    "        deep_pdfs.append(deep_density(z_range))\n",
    "        \n",
    "        plt.close()\n",
    "        plt.plot(z_range, deep_density(z_range), lw = 3)\n",
    "        plt.xlabel(\"Spectroscopic Redshift\")\n",
    "        plt.ylabel(\"Probability Density\")\n",
    "        plt.title(f\"Position: {deep_position[i]} in Deep SOM Weight: {counts[i]}\")\n",
    "        if save_diagram != False:\n",
    "            plt.savefig(f\"D:/SPHEREx_SOM/record/5th_exploration/mapping/deep_{deep_position[i]}.jpg\", bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "    combined_pdf = (counts / np.sum(counts)).reshape(-1, 1) * np.array(deep_pdfs)\n",
    "    \n",
    "    plt.close()\n",
    "    for i in combined_pdf:\n",
    "        plt.plot(z_range, i, lw = 1, alpha = 0.4, c = \"k\")\n",
    "    plt.plot(z_range, np.sum(combined_pdf , axis = 0), lw = 2, c = \"k\")\n",
    "    plt.xlabel(\"Spectroscopic Redshift\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.title(f\"Combined PDFs from Deep SOM\")\n",
    "    if save_diagram != False:\n",
    "        plt.savefig(f\"D:/SPHEREx_SOM/record/5th_exploration/mapping/combined_{shallow_position}.jpg\", bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(z_range, shallow_density(z_range), lw = 2, c = \"r\", label = \"Original PDF\")\n",
    "    plt.plot(z_range, np.sum(combined_pdf , axis = 0), lw = 2, c = \"k\", label = \"Combined PDF\")\n",
    "    plt.xlabel(\"Spectroscopic Redshift\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.title(f\"PDF Comparison\")\n",
    "    plt.legend()\n",
    "    if save_diagram != False:\n",
    "        plt.savefig(f\"D:/SPHEREx_SOM/record/5th_exploration/mapping/pdf_comparison.jpg\", bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return deep_position, deep_pdfs, combined_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4fab8f52-7a80-4030-81ee-7a8169ca7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_cells(data, err, info_data, file, save_diagram, position, bin_size = 3):\n",
    "    with open(file, \"rb\") as fh:\n",
    "        record = pickle.load(fh)\n",
    "\n",
    "    som = record[\"som\"]\n",
    "    b_scale = record[\"b_scale\"]\n",
    "    dim = record[\"dim\"] \n",
    "    lupmag = -np.arcsinh(data / (2 * b_scale  * err))\n",
    "    proc_data = (lupmag - np.mean(lupmag, axis=0)) / np.std(lupmag, ddof = 1, axis=0)\n",
    "    \n",
    "    if len(list(list(record[\"prop_map\"].items())[0][1].keys())[0]) != 3:\n",
    "        proc_err = np.absolute(-1 / (2 * b_scale  * err) / np.sqrt((data / (2 * b_scale * err)) ** 2 + 1) * err)\n",
    "        proc_err = proc_err / np.std(lupmag, ddof = 1, axis=0)\n",
    "    \n",
    "        print(f\"Topological error: {som.topographic_error(proc_data)}\")\n",
    "        print(f\"Quantization error: {som.quantization_error(proc_data)}\")\n",
    "        print(f\"Topological error: {record[\"topo_err\"]}\")\n",
    "        print(f\"Quantization error: {record[\"quan_err\"]}\")\n",
    "        \n",
    "        labels_map = som.labels_map(proc_data, proc_err, tuple(map(tuple, np.concatenate((np.expand_dims(info_data[\"HSC_i_MAG\"].values, axis = 1), \n",
    "                                                                                          np.expand_dims(info_data[\"z_true\"].values, axis = 1), \n",
    "                                                                                          np.expand_dims(np.array([i for i in range(0, proc_data.shape[0])]), axis = 1)), axis = -1))))\n",
    "        record[\"prop_map\"] = labels_map\n",
    "        \n",
    "        try:\n",
    "            with open(file, 'wb') as fh:\n",
    "                pickle.dump(record, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt caught, data saved.')\n",
    "    else:\n",
    "        labels_map = record[\"prop_map\"]\n",
    "\n",
    "    x = np.arange(position[0] - bin_size // 2, position[0] + bin_size // 2 + 1)\n",
    "    y = np.arange(position[1] - bin_size // 2, position[1] + bin_size // 2 + 1)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    positions = [tuple(i) for i in list(np.concatenate((xv.reshape(-1, 1),yv.reshape(-1, 1)), axis = -1))]\n",
    "\n",
    "    bin_redshifts = np.array([])\n",
    "    \n",
    "    skip = True\n",
    "    for i in labels_map.keys():\n",
    "        if i in positions:\n",
    "            properties = np.array(list(labels_map[i].keys()))\n",
    "            z_min = np.min(properties[:, 1])\n",
    "            z_max = np.max(properties[:, 1])\n",
    "            skip = False\n",
    "            bin_redshifts = np.concatenate((bin_redshifts, properties[:, 1]))\n",
    "\n",
    "    plt.hist(bin_redshifts, bins = 30, range = (np.min(info_data[\"z_true\"]), np.max(info_data[\"z_true\"])), density = True, alpha = 0.6, color='#1abc9c')\n",
    "    # if properties[:,1].shape[0] > 1:\n",
    "    #     density = gaussian_kde(properties[:,1])\n",
    "    #     z_range = np.linspace(np.min(info_data[\"z_true\"]), np.max(info_data[\"z_true\"]), 1000)\n",
    "    #     pdf = density(z_range)\n",
    "    #     plt.plot(z_range, pdf, lw = 2, c = '#9b59b6')\n",
    "    plt.xlabel(\"Spectroscopic Redshift\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    plt.title(f\"Mean: {round(np.mean(bin_redshifts), 5)} Median: {round(np.median(bin_redshifts), 5)} Std: {round(np.std(bin_redshifts, ddof = 1) / (1 + np.mean(bin_redshifts)), 5)} Total: {len(bin_redshifts)}\")\n",
    "    plt.axvline(x = np.mean(bin_redshifts), c ='#f1c40f', label = \"Mean\", lw = 2)\n",
    "    plt.axvline(x = np.median(bin_redshifts), c = '#e74c3c', label = \"Median\", lw = 2)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1702c2b3-f830-4e6a-b9f7-4fb4252bf26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_85192\\2517715244.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  shallow_info = df_L3_info[-pd.DataFrame(data_all[:, 0::2]).isna()[0]]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_85192\\2517715244.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  deep_info = df_L3_info[-pd.DataFrame(data_deep[:, 0::2]).isna()[0]]\n"
     ]
    }
   ],
   "source": [
    "shallow_data = pd.DataFrame(data_all[:, 0::2]).dropna().to_numpy()\n",
    "shallow_info = df_L3_info[-pd.DataFrame(data_all[:, 0::2]).isna()[0]]\n",
    "shallow_noiseless = data_noiseless[-pd.DataFrame(data_all[:, 0::2]).isna()[0]]\n",
    "shallow_err = np.tile(data_all[0, 1::2],  (shallow_data.shape[0], 1))\n",
    "\n",
    "deep_data = pd.DataFrame(data_deep[:, 0::2]).dropna().to_numpy()\n",
    "deep_info = df_L3_info[-pd.DataFrame(data_deep[:, 0::2]).isna()[0]]\n",
    "deep_noiseless = data_noiseless[-pd.DataFrame(data_deep[:, 0::2]).isna()[0]]\n",
    "deep_err = np.tile(data_deep[0, 1::2],  (deep_data.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a00a0-aef0-4018-9df2-3977c4af894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_visual(file = \"D:/SPHEREx_SOM/record/6th_exploration/SOM/chi2_lup_deep_70_1.3_1_5_10.pkl\", save_diagram = True, mode = \"median\", figure_size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c46b1b-f048-4dac-92c2-2c5caf9aa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cells(data = shallow_data, err = shallow_err, info_data = shallow_info, position = (30, 35), file = \"D:/SPHEREx_SOM/record/6th_exploration/SOM/chi2_lup_shallow_70_3.0_0.2_9_1000.pkl\", bin_size = 3, save_diagram = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d649dc-24c6-4e37-ad6d-98c89594ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i in range(0, 70):\n",
    "    weights.append(into_cell(data = shallow_data, err = shallow_err, info_data = shallow_info, position = (i, 35), file = \"D:/SPHEREx_SOM/record/6th_exploration/SOM/chi2_lup_shallow_70_3.0_0.2_9_1000.pkl\", save_diagram = True, noiseless_data = shallow_noiseless))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89605f67-e4ae-4d93-b14e-ecc0fea726fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i in range(0, 50):\n",
    "    weights.append(into_cell(data = deep_data , err = deep_err, info_data = deep_info, position = (40, i), file = \"D:/SPHEREx_SOM/record/5th_exploration/SOM/chi2_lup_deep_50_0.9_0.4_10_8.pkl\", save_diagram = True, noiseless_data = deep_noiseless))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3076b-4ab2-435c-b9af-0f38f1a26cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = into_cell(data = deep_data , err = deep_err, info_data = deep_info, position = (27, 48), file = \"D:/SPHEREx_SOM/record/5th_exploration/SOM/chi2_lup_deep_50_0.9_0.4_10_4.pkl\", save_diagram = True, noiseless_data = deep_noiseless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b656081-a83b-4fd7-a53e-a0ef5e063a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.autumn\n",
    "for i in range(len(weights[0:11])):\n",
    "    try:\n",
    "        plt.plot(data_1sig[:, 0], weights[0:11][10 - i], c = colormap((10 - i) / len(weights[0:11])))\n",
    "    except:\n",
    "        pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c967f92-8622-4212-a5d3-4065942daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.autumn\n",
    "for i in range(len(weights[10:20])):\n",
    "    try:\n",
    "        plt.plot(data_1sig[:, 0], weights[10:20][9 - i], c = colormap((9 - i) / len(weights[10:20])))\n",
    "    except:\n",
    "        pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e661da9-58e5-437a-86a8-0deebdeeda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_map(data = deep_data, err = deep_err, info_data = deep_info, file = \"D:/SPHEREx_SOM/record/5th_exploration/SOM/chi2_lup_deep_50_0.9_0.4_10_8.pkl\", save_diagram = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c3fe7-9a6a-4e4e-9248-c5c75c1fafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_map(data = shallow_data, err = shallow_err, info_data = shallow_info, file = \"D:/SPHEREx_SOM/record/4th_exploration/SOM/chi2_lup_shallow_30_1.6_0.02_1000_2.pkl\", save_diagram = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeabd9d-29af-470e-acb7-8b373b60fef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapped_cells, deep_pdfs, combined_pdf = mapping(shallow_file = \"D:/SPHEREx_SOM/record/5th_exploration/SOM/chi2_lup_shallow_50_0.8_0.5_1000_5.pkl\",\n",
    "                       deep_file = \"D:/SPHEREx_SOM/record/5th_exploration/SOM/chi2_lup_deep_50_0.9_0.4_10_4.pkl\", shallow_data = shallow_data,\n",
    "                       deep_data = deep_data, shallow_err = shallow_err, deep_err = deep_err, shallow_position = (20, 4), info_data = shallow_info, save_diagram = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a5ada-0151-4dbd-b681-c88cdef25a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
